\documentclass[12pt,a4paper,oneside]{article}


% Float
\usepackage[top=1in, bottom=1in, left=0.6in, right=0.6in]{geometry}
\usepackage{parskip} % better separation of two paragraphs
\setlength{\parindent}{0cm} % no left indent at paragraph beginning
\usepackage{multicol}

% Page style
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\rhead{Team 25}
\lhead{Advanced Systems Lab}
\rfoot{\thepage}
\usepackage{tcolorbox}

% Bibliography Style
\usepackage[colorlinks = true,citecolor = blue]{hyperref}
%\usepackage[round,longnamesfirst, sort]{natbib}

% Mathematics
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}

\usepackage[utf8]{inputenc}
\usepackage{tabularx}
\usepackage{booktabs}
\usepackage{multirow}
%\usepackage[framed, numbered, autolinebreaks, useliterate]{mcode}
\usepackage{pdfpages}
\usepackage{color}
\usepackage{qtree}

\usepackage{xcolor}
\usepackage{colortbl}

\usepackage{pifont}% http://ctan.org/pkg/pifont
\newcommand{\cmark}{\ding{51}}%
\usepackage{amsmath, nccmath}

\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}%horizontal line with 0.5mm thickness



\begin{document}
	\section*{Cost analysis}
	
	\textbf{Define}
	\begin{itemize}
		\item $n$ - number of points in the dataset
		\item $k$ - parameter of the LOF algorithm
		\item $dim$ - dimensionality of the dataset
	\end{itemize}
	
	\begin{table}[h!]
		\centering
	\begin{tabular}{l|c|cccc}
		\toprule
		% KB = 1000B
		% MB = 1000000B
		Name & Size [bytes] &&&& \\
		&  &L1 & L2 & L3& L4 \\
		&  &32KB & 256KB & 6MB& 128MB\\
		\midrule
		input points ptr &  $8\times n \times dim$  & 2000 & 16000&375000& 8000000\\
		distances indexed ptr  & $8\times n \times n$  &64&179&867 & 4000\\
		k distances indexed ptr  & $8\times n$ &4000&32000&750000&16000000\\
		neighborhood index table ptr  & $2\times n \times k$  &3200&25600&600000&12800000\\
		reachability distances indexed ptr  &  $8\times n \times n$  &64&179&867 & 4000\\
		lrd score table ptr  & $8\times n$ &4000&32000&750000&16000000\\
		lof score table ptr  & $8\times n$ &4000&32000&750000&16000000\\
		\bottomrule
		\textbf{Total}  & \multicolumn{3}{c}{$8\cdot n\cdot ( 3 + dim + 0.25k + 2 n  )$} &&\\
		\bottomrule
	\end{tabular}
	\caption{Data used by the algorithms. \newline 
		assume sizeof(int) = 2, sizeof(double) = 4. Assume dim = 2,  k = 5}
	\end{table}
	
	\textbf{Questions:}
	
	\begin{itemize}
		\item  at what values of $n, k, dim$ will the data stop fitting in different cache levels?
		\item what is the maximum number of objects that have to be in the memory simultaneously?
	\end{itemize}
	
		\begin{table}[h!]
			\centering
			\begin{tabular}{ll|cccccccc}
				\toprule
				operation& name & \multicolumn{2}{c}{FV} & \multicolumn{2}{c}{PR}  & \multicolumn{2}{c}{UB}  & \multicolumn{2}{c}{AS} \\
				&& lat & thr& lat & thr& lat & thr & lat & thr \\
				\midrule
				addition & FADD& & & && && 3 & 1 \\
				mul  & FMUL &&&&&&&5&1\\
				division & FDIV& & & && && 7-27 &  7-27\\
				fma & & & & && &&& \\
				sqrt &FSQRT& & & && &&27& 1\\
				comparison & FCOM  & & & && &&1 & 1\\
				load from L1 & & & & && &&& \\
				load from L2 && & & && &&& \\
				load from L3 && & & && &&& \\
				\bottomrule 
				% 1.3 (4)	3.4 (10)	13.0
				%  45.6      28.8    19.3 ?
				% QUESTION: bandwidth: cache vs memory or cache vs cache ?
			\end{tabular}
			\caption{ throughput - reciprocal throughput from Aigner's instruction tables}
		\end{table}
	
	AS: Newhalem i core 7
	TODO: add table with the information about operations for our computers / systems
	
	\begin{table}[h!]
		\centering
		\footnotesize
		\begin{tabular}{lcccc}
			\toprule
			Function & Denote& Cost Analysis& \textcolor{red}{Flops} &   \textcolor{red}{Run times} \\
			\midrule
			% EuclideanDistance &  $C^{eucl}$ & $dim*( 3\times C^{add} + C^{mul} ) + C^{sqrt}$& $4\cdot dim + 1$ \\[2mm]
			
			\textbf{F1} & $C^{dist}$& $n\cdot\frac{n}{2} \cdot (dim*( 3\times C^{add} + C^{mul} ) + C^{sqrt})$ &  $n\times \frac{n}{2} ( 4\cdot dim + 1 )$ & \\[2mm]
			
			%ComputeKDistanceObject & $C^{obj}$ & $(n-1) \log(n-1)$ & ? \\[2mm]
			
			\textbf{F2} & $C^{obj All}$&$n\cdot (n-1) \log(n-1)$ & \textcolor{red}{$n(n-1) \log(n-1)$} &\\[2mm]
			
			\textbf{F3} & $C^{neighAll}$ & $ n\cdot ( (n-1) \cdot C^{compare} + k\cdot C^{add}) $ &   $n\times (n - 1)$ &  \\[2mm]
			
			%ComputeReachabilityDistanceObject & $C^{reach}$& $2 C^{compare} + 2C^{mul} + 2 C^{add}$ & 1 \\[2mm]
			
			\textbf{F4} & $C^{reachAll}$ & $n\cdot n \cdot C^{compare}$ &  $n^2$&  \\[2mm]
			
			\textbf{F5} & $C^{lrd}$& $2\cdot n \cdot C^{div} + n\cdot k \cdot C^{add} $ & $n(k + 2)$& \\[2mm]
			
			\textbf{F6} & $C^{Lof}$ & $2\cdot n \cdot C^{div} + n\cdot k \cdot C^{add}$ & $n( k + 2 )$& \\[2mm]
			\bottomrule
			
			\textbf{Total} & \multicolumn{3}{c}{$C^{Lof} + C^{lrd} + C^{reachAll} + C^{neighAll} + C^{obj All} + C^{dist}$ }& \\
			
			\bottomrule
		\end{tabular}	
		%\caption{ComputePairwiseDistances depends on the metrics used}
	\end{table}
	
	\textbf{Questions}
	\begin{itemize}
		\item \textbf{ComputeKDistanceObject} should I count accessing array \textit{distances indexed ptr} num pts times?
	\end{itemize}
	
	Which flags: 

	
	\section*{Bottlenecks}
	
	\begin{itemize}
		\item Compute Pairwise Distance
		\item Compute Reachability Density
	\end{itemize}
	
	\section*{Compilers \& flags/Processors}
	
	\section*{Roofline}
	AS work in progress
	
		\begin{table}[h!]
			\centering
			\scriptsize
			
			\begin{tabular}{lccccc}
				\toprule
				Function & $W(n)$ & $Q(n)$ & $I(n)$ & $T(n)$ & $P(n)$\\
				\midrule
				
				F1 &$n \cdot \frac{n}{2} ( 4\cdot dim + 1 )$ & $8(n^2 + n\cdot dim)$& $\frac{dim}{4}$&
				$\frac{1}{2}n\cdot n\cdot(lat^{sqrt} + dim(3\frac{lat^{add}}{thr^{add}} + \frac{lat^{mul}}{thr^{mul}}))$ & $\frac{4\cdot dim + 1}{ lat^{sqrt} + dim(3\frac{lat^{add}}{thr^{add}} + \frac{lat^{mul}}{thr^{mul}}) }$ \\[5mm]
				
				\textbf{F2} & $n(n-1) \log(n-1)$  &$8(n^2 + n)$ & $\mathbf{O(\log(n))}$& $n(n-1) \log(n-1)\frac{lat^{comp}}{thr^{comp}}$&  $\frac{thr^{comp}}{lat^{comp}}$\\[5mm]
				
				F3 &  $n\times (n - 1)$ &$10n^2 + 8n$& $\frac{1}{10}$ & $n\cdot(n-1)\frac{lat^{comp}}{thr^{comp}}$ & $\frac{thr^{comp}}{lat^{comp}}$\\[5mm]
				
				F4 & $n^2$ &$8(n^2 + 2n)$ & $\frac{1}{8}$& $n^2\frac{lat^{comp}}{thr^{comp}}$ &$\frac{thr^{comp}}{lat^{comp}}$\\[5mm]
				
				F5 &  $n(k + 2)$ & $2nk + 16n$ &  $\frac{k + 2}{k+8}\approx 1$ & $n\cdot(2\cdot lat^{div} + k\frac{lat^{add}}{th^{add}})$& $\frac{k + 2}{  k\frac{lat^{add}}{th^{add}} + 2\cdot lat^{div} }$\\[5mm]
				
			    F6 & $n(k + 2)$ &  $2nk + 16n$& $\frac{k + 2}{k+8}\approx 1$   & $n\cdot(2\cdot lat^{div} + k\frac{lat^{add}}{th^{add}})$& $\frac{k + 2}{  k\frac{lat^{add}}{th^{add}} + 2\cdot lat^{div}  }$ \\[5mm]
				
				\bottomrule
			\end{tabular}	
			\caption{To compute $P(n)$ I have assumed Hashwell process same as introduced during the lecture. $T(n)$ is computed as $num op \cdot latency \cdot throughput$}
		\end{table}
		
		\begin{itemize}
			\item  \textbf{Compute bound} if it has high operational intensity: - \textbf{F2}?
			\item  \textbf{Memory bound} if it has low operational intensity: -  \textbf{F1},  \textbf{F3}, \textbf{F4}, \textbf{F5}, \textbf{F6}
		\end{itemize}
		
		\section*{Memory Optimization}
		
		\subsection*{Distance Calculation}
		
		\textbf{Denote}
		\begin{itemize}
			\item $B_n$: number of points loaded in a block
			\item $B_d$: number of dimensions, processed in a block
			\item $L$: cache size in bytes
		\end{itemize}
		Working set [bytes]: $2 \cdot B_n \cdot B_d \cdot sizeof(double) \rightarrow$ fits in cache $\iff B_n \cdot B_d \leq \frac{L}{16} \overset{\text{cache size} =32 KB}{=} 2000 $
		
\newpage
\section*{Meeting Notes 2.05.2020}

\begin{enumerate}
	\item  KD-trees \& Lattice: the main goal of the project is to use the techniques discussed during the lectures to improve the performance. Consequently - algorithmic changes are nice add ons but not mandatory if they take too much time
	\item KD-trees, performance measurement: measure execution time with and without building the index tree.
	\item KD-trees: for certain non-essential parts of the code, it is possible to use existing libraries instead of implementing everything from scratch
	\item Performance measurement: both cold and hot cache measurements can be included for comparison
	\item Performance plots: better to use medians and (or) boxplots to account for the runtime variability.
	\item Try to show peak performance on the plots !
	\item Try \textit{perf} (linux) for code profiling
	\item Compilation: check whether compiler performs vectorization
	\item Determine which functions are compute and which are memory bound. For memory  bound functions try \textbf{memory blocking}
	\item Python benchmark: make sure sklearn implementation does not use multiple cores. (BLAS ?) 
	\item \textbf{Evaluation:} does not necessarily depend on the achieved speedup. Important: evaluate what to try for which functions and explain why or why not different methods might work.
	
\end{enumerate}
			
\end{document}